{"cells":[{"cell_type":"markdown","metadata":{"id":"a62AxKzoNgdg"},"source":["# F1 Tenth Gymn Environment"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35399,"status":"ok","timestamp":1685091595985,"user":{"displayName":"Pantelis Kaplanoglou","userId":"03940930329359759255"},"user_tz":-180},"id":"k2taBUomqJHh","outputId":"3a0989ad-c59f-4e5a-84ce-41860d91189c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n","Current dir:  /content/gdrive/My Drive/Colab Notebooks/Risto\n","--------------------------------------------------------------------------------\n","'Autonomous Racing for F1Tenth.ipynb'   LICENSE\n"," config_example_map.yaml\t        maps\n"," custom\t\t\t\t        mllib\n"," Dockerfile\t\t\t        models\n"," docs\t\t\t\t        params.yaml\n"," envs\t\t\t\t        required_packages_colab.txt\n"," example_map.png\t\t        required_packages.txt\n"," example_map.yaml\t\t        required_packages_working.txt\n"," example_waypoints.csv\t\t        RLBox2D_v3.ipynb\n"," f110gym\t\t\t        setup.py\n"," f1tenth_racetracks\t\t        stable_baselines3\n"," HelloRacing.py\n","________________________________________________________________________________\n","/bin/bash: nvidia-smi: command not found\n"]}],"source":["# Mount GDrive, change directory and check contents of folder.\n","import os\n","from google.colab import drive, files\n","\n","PROJECT_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/Risto\"\n","\n","drive.mount('/content/gdrive/')\n","os.chdir(PROJECT_FOLDER)\n","print(\"Current dir: \", os.getcwd())\n","print(\"-\"*80)\n","!ls\n","print(\"_\"*80)\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"markdown","source":["## Required Libaries\n","We check for the proper versions of the installed Python packages."],"metadata":{"id":"kRlgQ8J8r7_w"}},{"cell_type":"code","source":["!pip list | grep -E \"librosa|numpy|tensorflow|torch\"\n","print(\"-\"*40)\n","!pip list | grep -E \"gym|gymnasium|pygame\"\n","print(\"-\"*40)\n","!pip list | grep -E \"Pillow|scipy|numba|pyyaml|pyglet|wandb|shapely|opencv-python|tensorboard|pandas|shimmy\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9AlF2DX4sF4j","executionInfo":{"status":"ok","timestamp":1685091991786,"user_tz":-180,"elapsed":4404,"user":{"displayName":"Pantelis Kaplanoglou","userId":"03940930329359759255"}},"outputId":"b4448d21-3a91-4e28-9c28-ea6ec294d00e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["librosa                       0.10.0.post2\n","numpy                         1.22.4\n","tensorflow                    2.12.0\n","tensorflow-datasets           4.9.2\n","tensorflow-estimator          2.12.0\n","tensorflow-gcs-config         2.12.0\n","tensorflow-hub                0.13.0\n","tensorflow-io-gcs-filesystem  0.32.0\n","tensorflow-metadata           1.13.1\n","tensorflow-probability        0.20.1\n","torch                         2.0.1+cu118\n","torchaudio                    2.0.2+cu118\n","torchdata                     0.6.1\n","torchsummary                  1.5.1\n","torchtext                     0.15.2\n","torchvision                   0.15.2+cu118\n","----------------------------------------\n","numba                         0.57.0\n","opencv-python                 4.7.0.72\n","opencv-python-headless        4.7.0.72\n","pandas                        1.5.3\n","pandas-datareader             0.10.0\n","pandas-gbq                    0.17.9\n","Pillow                        9.0.1\n","pyglet                        1.4.10\n","scipy                         1.10.1\n","shapely                       2.0.1\n","sklearn-pandas                2.2.0\n","tensorboard                   2.12.2\n","tensorboard-data-server       0.7.0\n","tensorboard-plugin-wit        1.8.1\n","wandb                         0.15.3\n","----------------------------------------\n","gym                           0.17.0\n","gym-notices                   0.0.8\n","gymnasium                     0.28.1\n","pygame                        2.4.0\n"]}]},{"cell_type":"markdown","source":["### Remove Libraries\n","We remove libraries to install their proper versions"],"metadata":{"id":"0SwvQ8fxs_CP"}},{"cell_type":"code","source":["!pip uninstall Pillow -y\n","!pip uninstall pyyaml -y\n","!pip uninstall pyglet -y\n","!pip uninstall gym -y\n","!pip uninstall numba -y\n","!pip uninstall numpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6EfYo8b_riZE","executionInfo":{"status":"ok","timestamp":1685091612880,"user_tz":-180,"elapsed":9753,"user":{"displayName":"Pantelis Kaplanoglou","userId":"03940930329359759255"}},"outputId":"9e362859-c4e7-47c2-b851-61845957adeb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: Pillow 8.4.0\n","Uninstalling Pillow-8.4.0:\n","  Successfully uninstalled Pillow-8.4.0\n","Found existing installation: PyYAML 6.0\n","Uninstalling PyYAML-6.0:\n","  Successfully uninstalled PyYAML-6.0\n","\u001b[33mWARNING: Skipping pyglet as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mFound existing installation: gym 0.25.2\n","Uninstalling gym-0.25.2:\n","  Successfully uninstalled gym-0.25.2\n","Found existing installation: numba 0.56.4\n","Uninstalling numba-0.56.4:\n","  Successfully uninstalled numba-0.56.4\n"]}]},{"cell_type":"markdown","source":["### Required Libraries\n"],"metadata":{"id":"qEPWa11pCj5o"}},{"cell_type":"code","source":["!pip install -r required_packages_colab.txt"],"metadata":{"id":"xpwmSOs0HJRd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Re-Mount After Restart\n","After restarting the runtime, we check again the installed Python packages to confirm that the requirements are installed."],"metadata":{"id":"0095vR2KtpJx"}},{"cell_type":"code","source":["import os\n","from google.colab import drive, files\n","\n","PROJECT_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/Risto\"\n","\n","drive.mount('/content/gdrive/')\n","os.chdir(PROJECT_FOLDER)\n","\n","!pip list | grep -E \"gym|gymnasium|pygame\"\n","print(\"-\"*40)\n","!pip list | grep -E \"Pillow|scipy|numba|pyyaml|pyglet|wandb|shapely|opencv-python|tensorboard|pandas|shimmy\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Efe1x1v-_-TN","executionInfo":{"status":"ok","timestamp":1685092020580,"user_tz":-180,"elapsed":8077,"user":{"displayName":"Pantelis Kaplanoglou","userId":"03940930329359759255"}},"outputId":"26cd219b-8f87-4713-910b-e3222b889793"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","gym                           0.17.0\n","gym-notices                   0.0.8\n","gymnasium                     0.28.1\n","pygame                        2.4.0\n","----------------------------------------\n","numba                         0.57.0\n","opencv-python                 4.7.0.72\n","opencv-python-headless        4.7.0.72\n","pandas                        1.5.3\n","pandas-datareader             0.10.0\n","pandas-gbq                    0.17.9\n","Pillow                        9.0.1\n","pyglet                        1.4.10\n","scipy                         1.10.1\n","shapely                       2.0.1\n","sklearn-pandas                2.2.0\n","tensorboard                   2.12.2\n","tensorboard-data-server       0.7.0\n","tensorboard-plugin-wit        1.8.1\n","wandb                         0.15.3\n"]}]},{"cell_type":"markdown","source":["## Install f110gym Package\n","This installs this project's subfolder /f110gym as a Python package. This is required to register f110 as a gym environment"],"metadata":{"id":"Z3rF7oDA3AR6"}},{"cell_type":"code","source":["!cat setup.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6M6EeBkuBLp","executionInfo":{"status":"ok","timestamp":1685092024915,"user_tz":-180,"elapsed":411,"user":{"displayName":"Pantelis Kaplanoglou","userId":"03940930329359759255"}},"outputId":"6a806046-cc98-4fc5-ad87-a69929bdaf32"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["from setuptools import setup\n","\n","setup(name='f110gym',\n","      version='0.2.1',\n","      author='Hongrui Zheng',\n","      author_email='billyzheng.bz@gmail.com',\n","      url='https://f1tenth.org',\n","      package_dir={'': 'f110gym'},\n","      install_requires=['gym==0.17.0',\n","\t\t        'numpy<=1.22.0,>=1.18.0',\n","                        'Pillow>=9.0.1',\n","                        'scipy>=1.7.3',\n","                        'numba>=0.55.2',\n","                        'pyyaml>=5.3.1',\n","                        'pyglet<1.5',\n","                        'pyopengl']\n","      )\n"]}]},{"cell_type":"code","source":["!pip install -e ."],"metadata":{"id":"XdaHBtkkACzZ","colab":{"base_uri":"https://localhost:8080/","height":574},"executionInfo":{"status":"ok","timestamp":1685092058481,"user_tz":-180,"elapsed":31708,"user":{"displayName":"Pantelis Kaplanoglou","userId":"03940930329359759255"}},"outputId":"1d353660-ee96-484e-887f-37e70685413b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content/gdrive/My%20Drive/Colab%20Notebooks/Risto\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: gym==0.17.0 in /usr/local/lib/python3.10/dist-packages (from f110gym==0.2.1) (0.17.0)\n","Collecting numpy<=1.22.0,>=1.18.0 (from f110gym==0.2.1)\n","  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from f110gym==0.2.1) (9.0.1)\n","Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from f110gym==0.2.1) (1.10.1)\n","Requirement already satisfied: numba>=0.55.2 in /usr/local/lib/python3.10/dist-packages (from f110gym==0.2.1) (0.57.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from f110gym==0.2.1) (5.4.1)\n","Requirement already satisfied: pyglet<1.5 in /usr/local/lib/python3.10/dist-packages (from f110gym==0.2.1) (1.4.10)\n","Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from f110gym==0.2.1) (3.1.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gym==0.17.0->f110gym==0.2.1) (1.16.0)\n","Requirement already satisfied: cloudpickle~=1.3.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.17.0->f110gym==0.2.1) (1.3.0)\n","Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.2->f110gym==0.2.1) (0.40.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet<1.5->f110gym==0.2.1) (0.18.3)\n","Installing collected packages: numpy, f110gym\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.4\n","    Uninstalling numpy-1.22.4:\n","      Successfully uninstalled numpy-1.22.4\n","  Running setup.py develop for f110gym\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","librosa 0.10.0.post2 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed f110gym-0.2.1 numpy-1.22.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}]},{"cell_type":"code","source":["import os\n","from google.colab import drive, files\n","\n","PROJECT_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/Risto\"\n","\n","drive.mount('/content/gdrive/')\n","os.chdir(PROJECT_FOLDER)\n","\n","!pip list | grep -E \"f110\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V8aWkGO529fi","executionInfo":{"status":"ok","timestamp":1685092076954,"user_tz":-180,"elapsed":5677,"user":{"displayName":"Pantelis Kaplanoglou","userId":"03940930329359759255"}},"outputId":"c9a23b04-64c4-4488-f88a-4ab8116b9ec9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","f110-gym                      0.2.1\n","f110gym                       0.2.1                 /content/gdrive/My Drive/Colab Notebooks/Risto/f110gym\n"]}]},{"cell_type":"markdown","source":["## Installing Virtual Display for Colab"],"metadata":{"id":"f_AW_YMp3kRD"}},{"cell_type":"code","source":["!apt install xvfb ffmpeg -y > /dev/null 2>&1\n","!pip install pyvirtualdisplay\n","!pip install piglet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jG4uv25ivZ0s","executionInfo":{"status":"ok","timestamp":1685092128394,"user_tz":-180,"elapsed":45766,"user":{"displayName":"Pantelis Kaplanoglou","userId":"03940930329359759255"}},"outputId":"69ee941c-5369-455d-af2a-b56152cd4a69"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyvirtualdisplay\n","  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n","Installing collected packages: pyvirtualdisplay\n","Successfully installed pyvirtualdisplay-3.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting piglet\n","  Downloading piglet-1.0.0-py2.py3-none-any.whl (2.2 kB)\n","Collecting piglet-templates (from piglet)\n","  Downloading piglet_templates-1.3.0-py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.5/67.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from piglet-templates->piglet) (3.0.9)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from piglet-templates->piglet) (23.1.0)\n","Requirement already satisfied: astunparse in /usr/local/lib/python3.10/dist-packages (from piglet-templates->piglet) (1.6.3)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from piglet-templates->piglet) (2.1.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse->piglet-templates->piglet) (0.40.0)\n","Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from astunparse->piglet-templates->piglet) (1.16.0)\n","Installing collected packages: piglet-templates, piglet\n","Successfully installed piglet-1.0.0 piglet-templates-1.3.0\n"]}]},{"cell_type":"markdown","source":["# Manual Restart and Re-Mount\n","You should manually restart the runtime and re-mount with this cell, this also will create the virtual display for Colab."],"metadata":{"id":"U_r-4BnX3qod"}},{"cell_type":"code","source":["import os\n","from google.colab import drive, files\n","from pyvirtualdisplay import Display\n","\n","PROJECT_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/Risto\"\n","\n","drive.mount('/content/gdrive/')\n","os.chdir(PROJECT_FOLDER)\n","\n","oDisplayDevice = Display(visible=0, size=(640, 480))\n","oDisplayDevice.start()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4guHskJ_vWAW","executionInfo":{"status":"ok","timestamp":1685092230559,"user_tz":-180,"elapsed":4932,"user":{"displayName":"Pantelis Kaplanoglou","userId":"03940930329359759255"}},"outputId":"17961715-2eca-4e97-f1ed-a30485607ef4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyvirtualdisplay.display.Display at 0x7f4aa42b7d90>"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"pGrVa7cezRhW"}},{"cell_type":"code","source":["import time\n","import numpy as np\n","from mllib import CFileStore\n","from envs import F1RaceTrack\n","from models.baseline import BabyDriver, PurePursuitPlanner\n","import numpy as np\n","from PIL import Image, ImageOps\n","from IPython.display import display\n","\n","\n","\n","physics = {'mass': 3.463388126201571, 'lf': 0.15597534362552312, 'tlad': 0.82461887897713965, 'vgain': 1.375}#0.90338203837889}\n","\n","oTrackFS = CFileStore(\".\")\n","oRaceTrack = F1RaceTrack(oTrackFS.File(\"config_example_map.yaml\") )\n","\n","planner = PurePursuitPlanner(oRaceTrack.config, (0.17145+0.15875)) \n","#planner = FlippyPlanner(speed=0.2, flip_every=1, steer=10)\n","#planner = BabyDriver()\n","\n","state, step_interval_secs, done, info = oRaceTrack.reset(planner)\n","nImage = oRaceTrack.env.render()\n","print(\"Started...\")\n","\n","laptime = 0.0\n","start = time.time()\n","\n","while not done:\n","  if oRaceTrack.env.is_period_start:\n","    print(oRaceTrack.env.tenth_index, nImage.shape)\n","    image = Image.fromarray(nImage)    \n","    image = ImageOps.flip(image)\n","    image = image.resize((nImage.shape[1]//2, nImage.shape[0]//2))\n","    display(image)\n","\n","  speed, steer = planner.plan(  state['poses_x'][0], state['poses_y'][0], state['poses_theta'][0]\n","                              , physics['tlad'], physics['vgain'])\n","  state, step_interval_secs, done, info = oRaceTrack.env.step(np.array([[steer, speed]]))\n","\n","  laptime += step_interval_secs\n","  nImage = oRaceTrack.env.render(mode='human')\n","\n","\n","    \n","nElapsed = time.time()-start \n","print(f\"Lap time: {laptime:.3f} simulation run time: {nElapsed:.3f}\")\n","\n","# Stop the virtual display when you're done\n","oDisplayDevice.stop()"],"metadata":{"id":"7020_KdcPUjS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Other"],"metadata":{"id":"2OqDyC385uFX"}},{"cell_type":"code","source":["pip install easyprocess"],"metadata":{"id":"k0bQL4FqQixt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import easyprocess\n","from pyvirtualdisplay.smartdisplay import SmartDisplay\n","\n","# Set up virtual display\n","display = SmartDisplay(visible=0, bgcolor='black')\n","display.start()\n","\n","# Set the display environment variable for EasyProcess\n","easyprocess.easyprocess.QUOTE_COMMAND = False\n","os.environ['DISPLAY'] = display.display"],"metadata":{"id":"IwWJzhBKPTU6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pyglet\n","pyglet.options[\"headless\"] = True"],"metadata":{"id":"AurMII5S32Ld"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def render_as_image(env):\n","    plt.imshow(env.render(mode='rgb_array'))\n","    plt.axis('off')\n","    plt.show()"],"metadata":{"id":"vS7lLXxaQ86i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pyvirtualdisplay\n","!pip install xvfbwrapper\n","!pip3 install PyOpenGL\n","!pip3 install PyOpenGL-accelerate"],"metadata":{"id":"BQFLVrXFQ9T2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"Tf2iymSxQ3Dm"}},{"cell_type":"code","source":["import time\n","from f110_gym.envs.base_classes import Integrator\n","import yaml\n","import gym\n","import numpy as np\n","from argparse import Namespace\n","\n","from numba import njit\n","import pyglet\n","pyglet.options[\"headless\"] = True\n","#from pyglet.gl import GL_POINTS"],"metadata":{"id":"_BtYQiMzFwGU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!apt install xvfb -y\n","!pip install pyvirtualdisplay\n","!pip install piglet\n","\n","from pyvirtualdisplay import Display\n","display = Display(visible=0, size=(1400, 900))\n","display.start()"],"metadata":{"id":"pdlJZlNvUI3k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall pyglet -Y"],"metadata":{"id":"1BfIBn4uU1mo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install pyglet==1.5"],"metadata":{"id":"T02EHSh3U5MJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pyvirtualdisplay import Display\n","_display = Display(visible=False, size=(1400, 900))\n","_ = _display.start()\n"],"metadata":{"id":"Rkmk3NgmUn4f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Stop the virtual display when you're done\n","display.stop()"],"metadata":{"id":"jW8nJxW3P4pr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install gymnasium==0.28.1\n","!sudo apt install swig && pip install \"git+https://github.com/pybox2d/pybox2d.git@2.3.10#egg=Box2D\"\n","!pip install gymnasium[box2d]==0.28.1"],"metadata":{"id":"9Rsr4oilzZkn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python --version\n","\n","!pip list | grep -E \"[bB]ox|gym\""],"metadata":{"id":"eA_Xu4auzezV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vzD6kLQQFtpF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from mllib.experiment import CMLExperimentConfig\n","\n","oConfig = CMLExperimentConfig(\"RLExperiment1.json\")\n","\n","for sKey in oConfig:\n","  print(sKey + \":\" + str(oConfig[sKey]))"],"metadata":{"id":"eG_NvkMhw2y2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kSkwxPsoqigg"},"source":["# Hyperparameters\n","\n","Create a new dictionary for a new experiment (e.g. CONFIG_5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kGmccmuZqhqM"},"outputs":[],"source":["from mllib import CFileStore\n","\n","CONFIG_HELLO = {   \"ModelName\": \"RL\"\n","                  ,\"ModelNumber\": 0\n","                  ,\"Data.ImageStackCount\": 4\n","                  ,\"Data.ActionRepeatCount\": 10\n","                  ,\"Data.EnvironmentResolution\": [96, 96]\n","                  ,\"RandomSeed\": 0\n","                \n","                  ,\"Training.RL.Gamma\": 0.99\n","                  ,\"Training.RL.Epochs\": 8\n","                  ,\"Training.RL.MaxSize\": 2000\n","                  ,\"Training.RL.BatchSize\": 128\n","                  ,\"Training.RL.EPS\": 0.1\n","                  ,\"Training.RL.LearningRate\": 0.001\n","                  ,\"Training.RL.NumEpisodes\": 30\n","              }\n","\n","\n","CONFIG_1 = {   \"ModelName\": \"RL\"\n","            ,\"ModelNumber\": 5\n","            ,\"Data.ImageStackCount\": 4\n","            ,\"Data.ActionRepeatCount\": 10\n","            ,\"Data.EnvironmentResolution\": [96, 96]\n","            ,\"RandomSeed\": 0\n","          \n","            ,\"Training.RL.Gamma\": 0.99\n","            ,\"Training.RL.Epochs\": 8\n","            ,\"Training.RL.MaxSize\": 2000\n","            ,\"Training.RL.BatchSize\": 128\n","            ,\"Training.RL.EPS\": 0.1\n","            ,\"Training.RL.LearningRate\": 0.001\n","            ,\"Training.RL.NumEpisodes\": 300\n","        }\n","\n","CONFIG_5 = {   \"ModelName\": \"RL\"\n","            ,\"ModelNumber\": 5\n","            ,\"Data.ImageStackCount\": 4\n","            ,\"Data.ActionRepeatCount\": 10\n","            ,\"Data.EnvironmentResolution\": [96, 96]\n","            ,\"RandomSeed\": 0\n","          \n","            ,\"Training.RL.Gamma\": 0.99\n","            ,\"Training.RL.Epochs\": 8\n","            ,\"Training.RL.MaxSize\": 2000\n","            ,\"Training.RL.BatchSize\": 128\n","            ,\"Training.RL.EPS\": 0.1\n","            ,\"Training.RL.LearningRate\": 0.001\n","            ,\"Training.RL.NumEpisodes\": 2000\n","        }\n","\n","CONFIG_6 = {   \"ModelName\": \"RL\"\n","            ,\"ModelNumber\": 6\n","            ,\"Data.ImageStackCount\": 4\n","            ,\"Data.ActionRepeatCount\": 10\n","            ,\"Data.EnvironmentResolution\": [96, 96]\n","            ,\"RandomSeed\": 0\n","          \n","            ,\"Training.RL.Gamma\": 0.99\n","            ,\"Training.RL.Epochs\": 8\n","            ,\"Training.RL.MaxSize\": 2000\n","            ,\"Training.RL.BatchSize\": 128\n","            ,\"Training.RL.EPS\": 0.1\n","            ,\"Training.RL.LearningRate\": 0.001\n","            ,\"Training.RL.NumEpisodes\": 1500\n","        }        \n","\n","CONFIG = CONFIG_HELLO        \n","\n","MODEL_NUMBER = CONFIG[\"ModelNumber\"]\n","sModelFolder = \"%s_%.2d\" % (CONFIG[\"ModelName\"], CONFIG[\"ModelNumber\"])\n","oModelFileStore = CFileStore(\"MLModels\").SubFS(sModelFolder)"]},{"cell_type":"markdown","metadata":{"id":"2IlwGXTgkLm6"},"source":["## Hyperparameters\n","This code uses global variables. We assign the hyperparams to them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rpQjpFPskLVa"},"outputs":[],"source":["img_stack=CONFIG[\"Data.ImageStackCount\"]\n","action_repeat = CONFIG[\"Data.ActionRepeatCount\"]\n","seed = CONFIG[\"RandomSeed\"]\n","\n","nImageWidth, nImageHeight = CONFIG[\"Data.EnvironmentResolution\"]\n","\n","transition = np.dtype([('s', np.float64, (img_stack, nImageWidth, nImageHeight)), \n","                       ('a', np.float64, (3,)), ('a_logp', np.float64),\n","                       ('r', np.float64), ('s_', np.float64, (img_stack, nImageWidth, nImageHeight))])\n","\n","\n","GAMMA = CONFIG[\"Training.RL.Gamma\"]\n","EPOCH = CONFIG[\"Training.RL.Epochs\"]              # beter than 10\n","MAX_SIZE = CONFIG[\"Training.RL.MaxSize\"]       ## CUDA out of mem for max_size=10000\n","BATCH = CONFIG[\"Training.RL.BatchSize\"] \n","EPS=CONFIG[\"Training.RL.EPS\"]\n","LEARNING_RATE = CONFIG[\"Training.RL.LearningRate\"]# bettr than 0.005 or 0.002 \n","NUM_EPISODES = CONFIG[\"Training.RL.NumEpisodes\"] #300\n","\n","# Duration of Episode ~20secs\n","#print(\"Estimated training time %d mins\" % ((NUM_EPISODES*20.0)/0.0))\n","print(\"Estimated training time %d hours\" % ((NUM_EPISODES*8.0)/2000.0))"]},{"cell_type":"markdown","metadata":{"id":"wZgRxNticPL_"},"source":["## CNN Model\n","This example uses the **Torch** framework. The class `Net` inherits from `nn.Module` where in its constructor the layers objects are created, in the same manner done in `keras`. The `forward` method is the `call` method of `keras`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"twQn60NwNgdr"},"outputs":[],"source":["# Import Pytorch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.distributions import Beta\n","from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n","import time\n","from collections import deque"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"riP07a0ENgds"},"outputs":[],"source":["class Net(nn.Module):\n","    \"\"\"\n","    Convolutional Neural Network for PPO\n","    \"\"\"\n","\n","    def __init__(self, img_stackg):\n","        super(Net, self).__init__()\n","        self.cnn_base = nn.Sequential(  # input shape (4, 96, 96)\n","            nn.Conv2d(img_stack, 8, kernel_size=4, stride=2),\n","            nn.ReLU(),  # activation\n","            nn.Conv2d(8, 16, kernel_size=3, stride=2),  # (8, 47, 47)\n","            nn.ReLU(),  # activation\n","            nn.Conv2d(16, 32, kernel_size=3, stride=2),  # (16, 23, 23)\n","            nn.ReLU(),  # activation\n","            nn.Conv2d(32, 64, kernel_size=3, stride=2),  # (32, 11, 11)\n","            nn.ReLU(),  # activation\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1),  # (64, 5, 5)\n","            nn.ReLU(),  # activation\n","            nn.Conv2d(128, 256, kernel_size=3, stride=1),  # (128, 3, 3)\n","            nn.ReLU(),  # activation\n","        )  # output shape (256, 1, 1)\n","        self.v = nn.Sequential(nn.Linear(256, 100), nn.ReLU(), nn.Linear(100, 1))\n","        self.fc = nn.Sequential(nn.Linear(256, 100), nn.ReLU())\n","        self.alpha_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n","        self.beta_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n","        self.apply(self._weights_init)\n","\n","    @staticmethod\n","    def _weights_init(m):\n","        if isinstance(m, nn.Conv2d):\n","            nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n","            nn.init.constant_(m.bias, 0.1)\n","\n","    def forward(self, x):\n","        x = self.cnn_base(x)\n","        x = x.view(-1, 256)\n","        v = self.v(x)\n","        x = self.fc(x)\n","        alpha = self.alpha_head(x) + 1\n","        beta = self.beta_head(x) + 1\n","\n","        return (alpha, beta), v"]},{"cell_type":"markdown","metadata":{"id":"7-PMoe0wczH6"},"source":["## Reinforcement Learning Agent\n","\n","This is the class that implements RL. You can notice the value function\n","as `target_v = r + GAMMA * self.net(next_s)` where GAMMA is the discount factor hyperparameter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7nmg6EcgNgdt"},"outputs":[],"source":["class Agent():\n","    \"\"\" Agent for training \"\"\"\n","    \n","    def __init__(self, device):\n","        self.training_step = 0\n","        self.net = Net(img_stack).double().to(device)\n","        self.buffer = np.empty(MAX_SIZE, dtype=transition)\n","        self.counter = 0\n","        self.device = device\n","        \n","        self.optimizer = optim.Adam(self.net.parameters(), lr=LEARNING_RATE)  ## lr=1e-3\n","\n","    def select_action(self, state):\n","        state = torch.from_numpy(state).double().to(self.device).unsqueeze(0)\n","        \n","        with torch.no_grad():\n","            alpha, beta = self.net(state)[0]\n","        dist = Beta(alpha, beta)\n","        action = dist.sample()\n","        a_logp = dist.log_prob(action).sum(dim=1)\n","\n","        action = action.squeeze().cpu().numpy()\n","        a_logp = a_logp.item()\n","        return action, a_logp\n","\n","\n","    def store(self, transition):\n","        self.buffer[self.counter] = transition\n","        self.counter += 1\n","        if self.counter == MAX_SIZE:\n","            self.counter = 0\n","            return True\n","        else:\n","            return False\n","\n","    def update(self):\n","        self.training_step += 1\n","\n","        s = torch.tensor(self.buffer['s'], dtype=torch.double).to(self.device)\n","        a = torch.tensor(self.buffer['a'], dtype=torch.double).to(self.device)\n","        r = torch.tensor(self.buffer['r'], dtype=torch.double).to(self.device).view(-1, 1)\n","        next_s = torch.tensor(self.buffer['s_'], dtype=torch.double).to(self.device)\n","\n","        old_a_logp = torch.tensor(self.buffer['a_logp'], dtype=torch.double).to(self.device).view(-1, 1)\n","\n","        with torch.no_grad():\n","            target_v = r + GAMMA * self.net(next_s)[1]\n","            adv = target_v - self.net(s)[1]\n","            # adv = (adv - adv.mean()) / (adv.std() + 1e-8)\n","\n","        for nEpochNumber in range(EPOCH):\n","            print(\"Agent updating. Epoch %d\" % (nEpochNumber + 1))\n","            for index in BatchSampler(SubsetRandomSampler(range(MAX_SIZE)), BATCH, False):\n","\n","                alpha, beta = self.net(s[index])[0]\n","                dist = Beta(alpha, beta)\n","                a_logp = dist.log_prob(a[index]).sum(dim=1, keepdim=True)\n","                ratio = torch.exp(a_logp - old_a_logp[index])\n","\n","                surr1 = ratio * adv[index]\n","                \n","                # clipped function\n","                surr2 = torch.clamp(ratio, 1.0 - EPS, 1.0 + EPS) * adv[index]\n","                action_loss = -torch.min(surr1, surr2).mean()\n","                value_loss = F.smooth_l1_loss(self.net(s[index])[1], target_v[index])\n","                loss = action_loss + 2. * value_loss\n","\n","                self.optimizer.zero_grad()\n","                loss.backward()\n","                self.optimizer.step()"]},{"cell_type":"markdown","metadata":{"id":"lRUgDT9tNgdt"},"source":["### Initializing Training Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ksim-oamNgdu"},"outputs":[],"source":["# Initializing Training Environment\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print('device: ', device)\n","\n","\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","np.random.seed(seed)\n","\n","\n","\n","env = gym.make('CarRacing-v2', verbose=0, render_mode='rgb_array')\n","state = env.reset()\n","print('env.action_space.shape: ', env.action_space.shape)\n","reward_threshold = env.spec.reward_threshold\n","print('reward_threshold', reward_threshold)"]},{"cell_type":"markdown","metadata":{"id":"EffRDQl3Ngdu"},"source":["### Preprocessing CarRacing Screenshots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HsuS8rj8Ngdu"},"outputs":[],"source":["# show what a preprocessed image looks like\n","frame, reward, terminated, truncated, info = env.step(np.array([2., 1., 1.]))\n","\n","print('frame.shape: ', frame.shape)\n","plt.subplot(1,2,1)\n","plt.imshow(frame)\n","plt.title('original image')\n","\n","#-------------------------------#\n","\n","def rgb2gray(rgb, norm=True):\n","        # rgb image -> gray [0, 1]\n","    gray = np.dot(rgb[..., :], [0.299, 0.587, 0.114])\n","    if norm:\n","        # normalize\n","        gray = gray / 128. - 1.\n","    return gray\n","\n","img_gray = rgb2gray(frame)\n","\n","#-------------------------------# \n","plt.subplot(1,2,2)\n","plt.title('preprocessed image')\n","\n","print('img.shape: ', img_gray.shape)\n","\n","# 96 x 96 black and white image\n","plt.imshow(img_gray, cmap='Greys')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"DqM4uc8GNgdv"},"source":["### Define Wrapper for Our Environment\n","The environment wrapper emulates each step of the episode with `env.step`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWl2trfMNgdv"},"outputs":[],"source":["class Wrapper():\n","    \"\"\"\n","    Environment wrapper for CarRacing \n","    \"\"\"\n","\n","    def __init__(self, env, p_bIsRendering=False):\n","        self.env = env  \n","        self.IsRendering = p_bIsRendering\n","\n","    def reset(self):\n","        self.counter = 0\n","        self.av_r = self.reward_memory()\n","\n","        self.die = False\n","        img_rgb, _ = self.env.reset()\n","        img_gray = rgb2gray(img_rgb)\n","        self.stack = [img_gray] * img_stack  # four frames for decision\n","        return np.array(self.stack)\n","\n","    def step(self, action):\n","        total_reward = 0\n","        for i in range(action_repeat):\n","            if self.IsRendering:\n","                self.env.render()\n","            img_rgb, reward, die, truncated, info = self.env.step(action)\n","            # don't penalize \"die state\"\n","            if die:\n","                reward += 100\n","            # green penalty\n","            if np.mean(img_rgb[:, :, 1]) > 185.0:\n","                reward -= 0.05\n","            total_reward += reward\n","            # if no reward recently, end the episode\n","            done = True if self.av_r(reward) <= -0.1 else False\n","            if done or die:\n","                break\n","        img_gray = rgb2gray(img_rgb)\n","        self.stack.pop(0)\n","        self.stack.append(img_gray)\n","        assert len(self.stack) == img_stack\n","        return np.array(self.stack), total_reward, done, die\n","\n","\n","    @staticmethod\n","    def reward_memory():\n","        # record reward for last 100 steps\n","        count = 0\n","        length = 100\n","        history = np.zeros(length)\n","\n","        def memory(reward):\n","            nonlocal count\n","            history[count] = reward\n","            count = (count + 1) % length\n","            return np.mean(history)\n","\n","        return memory"]},{"cell_type":"markdown","metadata":{"id":"0kdR7zQiePhG"},"source":["## Training Process\n","There is the `ppo_train` that runs the agent training process and the `save` that saves the trained state of the agent to be reloaded."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hu3k3cbXNgdw"},"outputs":[],"source":["def ppo_train(n_episodes=500, save_every=100):\n","    \n","    scores_deque = deque(maxlen=100)\n","    scores_array = []\n","    avg_scores_array = []    \n","\n","    timestep_after_last_save = 0\n","    \n","    time_start = time.time()\n","\n","    running_score = 0\n","    state = env_wrap.reset()\n","    \n","    i_lim = 0\n","    \n","    for i_episode in range(n_episodes):\n","        \n","        timestep = 0\n","        total_reward = 0\n","        \n","        ## score = 0\n","        state = env_wrap.reset()\n","\n","        while True:    \n","            \n","            action, a_logp = agent.select_action(state)\n","            next_state, reward, done, die  = env_wrap.step( \n","                action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n","\n","            if agent.store((state, action, a_logp, reward, next_state)):\n","                print('updating')\n","                agent.update()\n","            \n","            total_reward += reward\n","            state = next_state\n","            \n","            timestep += 1  \n","            timestep_after_last_save += 1\n","            \n","            if done or die:\n","                break\n","                \n","        running_score = running_score * 0.99 + total_reward * 0.01\n","\n","        scores_deque.append(total_reward)\n","        scores_array.append(total_reward)\n","\n","        avg_score = np.mean(scores_deque)\n","        avg_scores_array.append(avg_score)\n","        \n","        s = (int)(time.time() - time_start)        \n","        print('Ep. {}, Ep.Timesteps {}, Score: {:.2f}, Avg.Score: {:.2f}, Run.Score {:.2f}, \\\n","Time: {:02}:{:02}:{:02} '\\\n","            .format(i_episode, timestep, \\\n","                    total_reward, avg_score, running_score, s//3600, s%3600//60, s%60))  \n","       \n","        \n","        # Save episode is equal to \"save_every\" timesteps\n","        if i_episode+1 % save_every == 0:\n","\n","            suf = str(i_episode)\n","            save(agent, '', 'model_weights', suf)\n","            \n","        if np.mean(scores_deque) > reward_threshold:\n","            print(\"Solved environment! Running score is {:.2f}, Avg.Score: {:.2f} !\" \\\n","                  .format(running_score, avg_score))\n","            break\n","            \n","    return scores_array, avg_scores_array    \n","            \n"]},{"cell_type":"markdown","metadata":{"id":"khWP2tzSNgdw"},"source":["### Training \n","We should have a high number of NUM_EPISODES for a successful training.\n","Here is just 3 for preview of the process\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRSGqpAjNgdv"},"outputs":[],"source":["def save(agent, filename):\n","    torch.save(agent.net.state_dict(), filename)\n","\n","\n","def load(agent, filename):\n","    agent.net.load_state_dict(torch.load(filename))  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ieymzjqINgdw"},"outputs":[],"source":["IS_RETRAINING = False\n","\n","agent = Agent(device)\n","env_wrap = Wrapper(env)\n","\n","\n","\n","sModelStateFileName = \"model%d_weights.pth\" % MODEL_NUMBER\n","\n","\n","bMustTrain = (not os.path.exists(oModelFileStore.File(sModelStateFileName))) or IS_RETRAINING\n","\n","if bMustTrain:\n","  print(\"[>] Training\")\n","  scores, avg_scores  = ppo_train(n_episodes=NUM_EPISODES, save_every=100)\n","\n","  oModelFileStore.Serialize(\"Scores.pkl\", scores)\n","  oModelFileStore.Serialize(\"AverageScores.pkl\", avg_scores)\n","\n","  # Save latest model. We'll use it for testing\n","  save(agent, oModelFileStore.File(sModelStateFileName))\n","else:\n","  print(\"[>] Loading\")\n","  scores = oModelFileStore.Deserialize(\"Scores.pkl\")\n","  avg_scores = oModelFileStore.Deserialize(\"AverageScores.pkl\")\n","  load(agent, oModelFileStore.File(sModelStateFileName)) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4U1GBkXNgdx"},"outputs":[],"source":["%matplotlib inline\n","\n","if scores is not None:\n","  print('length of scores: ', len(scores), ', len of avg_scores: ', len(avg_scores))\n","\n","  fig = plt.figure()\n","  ax = fig.add_subplot(111)\n","  plt.plot(np.arange(1, len(scores)+1), scores, label=\"Score\")\n","  plt.plot(np.arange(1, len(avg_scores)+1), avg_scores, label=\"Avg on 100 episodes\")\n","  plt.legend(bbox_to_anchor=(1.05, 1)) \n","  plt.ylabel('Score')\n","  plt.xlabel('Episodes #')\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"8ggSvcQefUSF"},"source":["## Evaluation\n","There is a `load` method that loads the save state of the agent. And a `play` that runs an episode with the trained agent.\n","\n","Here the metric is the averaged reward of 10 episodes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGJrvCH1Ngdx"},"outputs":[],"source":["def play(env, agent, n_episodes):\n","    state = env_wrap.reset()\n","    \n","    scores_deque = deque(maxlen=n_episodes)\n","    scores = []\n","    \n","    for i_episode in range(1, n_episodes+1):\n","        state = env_wrap.reset()        \n","        score = 0\n","        \n","        time_start = time.time()\n","        \n","        while True:\n","            action, a_logp = agent.select_action(state)\n","            env.render()\n","            next_state, reward, done, die = env_wrap.step( \\\n","                action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n","\n","            state = next_state\n","            score += reward\n","            \n","            if done or die:\n","                break \n","\n","        s = (int)(time.time() - time_start)\n","        \n","        scores_deque.append(score)\n","        scores.append(score)\n","\n","        print('Episode {}\\tAverage Score: {:.2f},\\tScore: {:.2f} \\tTime: {:02}:{:02}:{:02}'\\\n","                  .format(i_episode, np.mean(scores_deque), score, s//3600, s%3600//60, s%60))\n","    return np.mean(scores_deque)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E4EgKekpNgdy"},"outputs":[],"source":["# We use the average score of 10 episodes as result, Don't change n_episodes!!!\n","total_avg_reward = play(env, agent, n_episodes=10)\n","\n","\n","# Print results in CSV format\n","with open(oModelFileStore.File(\"rewards.csv\"), 'w') as f:\n","    f.write('Id,Predicted\\n')\n","    f.write('CarRacing_public,{}\\n'.format(total_avg_reward))\n","    f.write('CarRacing_private,{}\\n'.format(total_avg_reward))\n","\n","import pandas as pd\n","df  = pd.read_csv(oModelFileStore.File(\"rewards.csv\"))\n","df.head()\n","\n","# Download file\n","from google.colab import files\n","files.download(oModelFileStore.File(\"rewards.csv\"))"]},{"cell_type":"markdown","metadata":{"id":"gtS8fiFrNgdy"},"source":["## Video Recording"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mR3nM6_ydGlo"},"outputs":[],"source":["def record(p_oVideoRecorder, p_oAgent):\n","    oVideoRecorderWrapper = Wrapper(p_oVideoRecorder, p_bIsRendering=True)\n","    score = 0\n","    \n","    time_start = time.time()\n","\n","    state = oVideoRecorderWrapper.reset()\n","    while True:\n","        action, a_logp = p_oAgent.select_action(state)\n","        next_state, reward, terminated, truncated = oVideoRecorderWrapper.step(action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n","        done = terminated or truncated\n","                \n","        state = next_state\n","        score += reward\n","                        \n","        if done:\n","          break \n","    p_oVideoRecorder.close()\n","    s = (int)(time.time() - time_start)        \n","# --------------------------------------------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4Fq4ddURlLW"},"outputs":[],"source":["from gymnasium.wrappers import RecordVideo\n","from moviepy import editor\n","\n","\n","VIDEO_PREFIX = \"model%d-video\" % MODEL_NUMBER\n","\n","env = gym.make('CarRacing-v2', verbose=0, render_mode='rgb_array')\n","oVideoRecorder = RecordVideo(env, oModelFileStore.BaseFolder, name_prefix=VIDEO_PREFIX, video_length=15000)\n","record(oVideoRecorder, agent)"]},{"cell_type":"code","source":["editor.ipython_display( oModelFileStore.File(\"%s-episode-0.mp4\" % VIDEO_PREFIX))"],"metadata":{"id":"0CiojI98fWYe"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z8HeuU26qk_p"},"outputs":[],"source":["from moviepy import editor\n","oVideoClip = editor.VideoFileClip(oModelFileStore.File(\"%s-episode-0.mp4\" % VIDEO_PREFIX))\n","oVideoClip.ipython_display(width=1024)"]}],"metadata":{"colab":{"provenance":[{"file_id":"16CHEQqa1WX4V3XipYaIPZrtr1lM41txw","timestamp":1684913606333}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}